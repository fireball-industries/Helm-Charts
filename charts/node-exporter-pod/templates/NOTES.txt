â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
â•šâ•â•     â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•   â•šâ•â•   â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•šâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•      â–ˆâ–ˆâ•”â•â•â•   â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•      â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                      â”‚
â”‚  ğŸ”¥ FIREBALL INDUSTRIES NODE EXPORTER - SUCCESSFULLY DEPLOYED ğŸ”¥                     â”‚
â”‚                                                                                      â”‚
â”‚  Because knowing your hardware is dying BEFORE it catches fire is surprisingly      â”‚
â”‚  useful in production environments where downtime costs actual money.               â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ DEPLOYMENT INFORMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Mode:           {{ .Values.deploymentMode | upper }}
  {{- if eq .Values.deploymentMode "daemonset" }}
  Coverage:       Running on EVERY node in your cluster
                  (Yes, even that one sketchy node you forgot about)
  {{- else if eq .Values.deploymentMode "deployment" }}
  Replicas:       {{ .Values.replicaCount }}
                  (Single instance - good for testing, not for production)
  {{- else }}
  Replicas:       {{ .Values.replicaCount }}
                  (StatefulSet mode - because you like complications)
  {{- end }}
  
  Preset:         {{ .Values.resourcePreset }}
  {{- if eq .Values.resourcePreset "edge-minimal" }}
                  (IoT/Raspberry Pi mode - minimal resource usage)
  {{- else if eq .Values.resourcePreset "edge-standard" }}
                  (Standard edge - because your industrial PC deserves monitoring)
  {{- else if eq .Values.resourcePreset "server" }}
                  (Full server mode - all the metrics, all the time)
  {{- else }}
                  (Custom configuration - you know what you're doing, right?)
  {{- end }}
  
  Namespace:      {{ include "node-exporter.namespace" . }}
  Release:        {{ .Release.Name }}

ğŸ“ˆ METRICS ENDPOINT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Service URL:    http://{{ include "node-exporter.fullname" . }}.{{ include "node-exporter.namespace" . }}.svc.cluster.local:{{ .Values.service.port }}/metrics
  Metrics Path:   {{ .Values.metricsPath }}
  Port:           {{ .Values.service.port }}

  {{- if eq .Values.deploymentMode "daemonset" }}
  
  ğŸ” Access per-node metrics:
  
    # Forward port from any node exporter pod
    kubectl port-forward -n {{ include "node-exporter.namespace" . }} \
      daemonset/{{ include "node-exporter.fullname" . }} {{ .Values.service.port }}:{{ .Values.service.port }}
    
    # Then access metrics locally
    curl http://localhost:{{ .Values.service.port }}/metrics
  
  {{- else }}
  
  ğŸ” Access metrics:
  
    # Forward port from the pod
    kubectl port-forward -n {{ include "node-exporter.namespace" . }} \
      deployment/{{ include "node-exporter.fullname" . }} {{ .Values.service.port }}:{{ .Values.service.port }}
    
    # Then access metrics locally
    curl http://localhost:{{ .Values.service.port }}/metrics
  
  {{- end }}

ğŸ” ENABLED COLLECTORS ({{ include "node-exporter.collectorCount" . }})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  {{- $preset := .Values.resourcePreset -}}
  {{- if and (ne $preset "custom") (hasKey .Values.resourcePresets $preset) }}
    {{- range (index .Values.resourcePresets $preset).collectors }}
  âœ“ {{ . }}
    {{- end }}
  {{- else }}
    {{- range .Values.collectors.enabled }}
  âœ“ {{ . }}
    {{- end }}
  {{- end }}
  {{- if .Values.collectors.optional.systemd }}
  âœ“ systemd (service health monitoring)
  {{- end }}
  {{- if .Values.collectors.optional.processes }}
  âœ“ processes (per-process metrics)
  {{- end }}
  {{- if .Values.collectors.optional.textfile }}
  âœ“ textfile (custom metrics from files)
  {{- end }}
  {{- if .Values.collectors.optional.ntp }}
  âœ“ ntp (time synchronization monitoring)
  {{- end }}
  {{- if .Values.collectors.optional.tcpstat }}
  âœ“ tcpstat (TCP connection states)
  {{- end }}
  {{- if .Values.collectors.optional.interrupts }}
  âœ“ interrupts (IRQ statistics)
  {{- end }}
  {{- if .Values.collectors.optional.thermal_zone }}
  âœ“ thermal_zone (temperature sensors) âš ï¸  IMPORTANT FOR EDGE!
  {{- end }}
  {{- if .Values.collectors.optional.ethtool }}
  âœ“ ethtool (NIC statistics)
  {{- end }}
  {{- if .Values.collectors.optional.wifi }}
  âœ“ wifi (wireless metrics)
  {{- end }}
  {{- if .Values.collectors.optional.rapl }}
  âœ“ rapl (power consumption)
  {{- end }}
  {{- if .Values.collectors.optional.supervisord }}
  âœ“ supervisord (process supervisor)
  {{- end }}

{{- if .Values.collectors.optional.thermal_zone }}

ğŸŒ¡ï¸  TEMPERATURE MONITORING: ENABLED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  âš ï¸  CRITICAL FOR INDUSTRIAL EDGE DEPLOYMENTS!
  
  Your edge device sitting in a metal enclosure on the factory floor with zero
  ventilation is NOT "running fine" at 85Â°C. That's called "pre-failure mode."
  
  Pro tip: If you can't comfortably hold your hand on the enclosure for 10 seconds,
  your hardware is cooking itself. Fix. Your. Cooling.
  
  Query temperature metrics:
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_hwmon_temp_celsius
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_thermal_zone_temp

{{- end }}

{{- if .Values.collectors.optional.textfile }}

ğŸ“ TEXTFILE COLLECTOR: ENABLED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Directory:      {{ .Values.collectors.collectorArgs.textfile.directory }}
  
  Add custom metrics from scripts or external tools:
  
    # Create a custom metric file
    echo 'backup_last_success_timestamp 1737446400' > \
      {{ .Values.collectors.collectorArgs.textfile.directory }}/backup.prom
    
    echo 'hardware_health_status{component="raid"} 1' >> \
      {{ .Values.collectors.collectorArgs.textfile.directory }}/hardware.prom
  
  See textfile-examples/ directory for scripts that generate:
    - Backup job status
    - Custom hardware health checks
    - Software license expiry monitoring
    - Integration with third-party tools

{{- end }}

{{- if .Values.serviceMonitor.enabled }}

ğŸ“Š PROMETHEUS SERVICEMONITOR: ENABLED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Your Prometheus Operator will automatically discover and scrape these metrics.
  
  Scrape Interval:  {{ .Values.serviceMonitor.interval }}
  Scrape Timeout:   {{ .Values.serviceMonitor.scrapeTimeout }}
  
  Verify ServiceMonitor:
    kubectl get servicemonitor -n {{ default (include "node-exporter.namespace" .) .Values.serviceMonitor.namespace }}

{{- end }}

ğŸ“Š GRAFANA DASHBOARDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Import these popular dashboards into Grafana:
  
  ğŸ“ˆ Node Exporter Full (ID: 1860)
     Comprehensive view of all node metrics
     https://grafana.com/grafana/dashboards/1860
  
  ğŸ“ˆ Node Exporter for Prometheus Dashboard (ID: 11074)
     Detailed system and hardware metrics
     https://grafana.com/grafana/dashboards/11074
  
  ğŸ“ˆ Custom Industrial Edge Dashboard
     Optimized for edge computing environments
     Import: ./dashboards/industrial-edge.json
  
  ğŸ“ˆ Hardware Health Dashboard
     Temperature, sensors, RAID, and disk health
     Import: ./dashboards/hardware-health.json

âš ï¸  RECOMMENDED ALERT RULES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Deploy these alert rules to catch issues before they become outages:
  
  ğŸš¨ High CPU Usage (>80% for 5m)
     100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
  
  ğŸš¨ High Memory Usage (>90%)
     (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
  
  ğŸš¨ Disk Space Critical (<10% free)
     100 - ((node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100) < 10
  
  ğŸš¨ High Disk I/O Latency (>100ms)
     rate(node_disk_io_time_seconds_total[5m]) > 0.1
  
  ğŸš¨ Network Errors (>1% error rate)
     rate(node_network_receive_errs_total[5m]) / rate(node_network_receive_packets_total[5m]) > 0.01
  
  {{- if .Values.collectors.optional.thermal_zone }}
  ğŸš¨ Temperature Warning (>70Â°C)
     node_hwmon_temp_celsius > 70
  
  ğŸš¨ Temperature Critical (>80Â°C)
     node_hwmon_temp_celsius > 80
     (Seriously, if you see this, your hardware is literally cooking)
  {{- end }}
  
  Complete alert rule templates available in:
    - alerts/alerts-hardware.yaml
    - alerts/alerts-filesystem.yaml
    - alerts/alerts-system.yaml
    {{- if .Values.collectors.optional.thermal_zone }}
    - alerts/alerts-temperature.yaml
    {{- end }}

ğŸ”§ QUICK COMMANDS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  View logs:
    kubectl logs -n {{ include "node-exporter.namespace" . }} -l app.kubernetes.io/name={{ include "node-exporter.name" . }}
  
  {{- if eq .Values.deploymentMode "daemonset" }}
  Check DaemonSet status:
    kubectl get daemonset -n {{ include "node-exporter.namespace" . }} {{ include "node-exporter.fullname" . }}
  
  View per-node deployment:
    kubectl get pods -n {{ include "node-exporter.namespace" . }} -l app.kubernetes.io/name={{ include "node-exporter.name" . }} -o wide
  {{- end }}
  
  Test metrics endpoint:
    curl http://localhost:{{ .Values.service.port }}/metrics | head -20
  
  Query specific metrics:
    # CPU usage
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_cpu_seconds_total
    
    # Memory
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_memory
    
    # Disk I/O
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_disk
    
    # Network
    curl -s http://localhost:{{ .Values.service.port }}/metrics | grep node_network

ğŸ’» POWERSHELL MANAGEMENT SCRIPTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Comprehensive cluster health analysis:
    .\scripts\analyze-cluster-health.ps1
  
  View metrics from all nodes:
    .\scripts\manage-node-exporter.ps1 -Action view-metrics
  
  Run health checks:
    .\scripts\manage-node-exporter.ps1 -Action health-check
  
  Test deployment:
    .\scripts\test-node-exporter.ps1

ğŸ“š DOCUMENTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  README.md               Complete setup and configuration guide
  COLLECTORS.md           Collector reference and configuration
  METRICS_REFERENCE.md    Metrics catalog and PromQL examples
  QUICK_REFERENCE.md      Quick command reference

ğŸ› TROUBLESHOOTING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  Pods not starting?
    â†’ Check RBAC: kubectl get clusterrole,clusterrolebinding | grep node-exporter
    â†’ Check node taints: kubectl describe nodes | grep Taints
  
  Metrics not appearing?
    â†’ Verify collectors: kubectl logs -n {{ include "node-exporter.namespace" . }} -l app.kubernetes.io/name={{ include "node-exporter.name" . }}
    â†’ Check host mounts: kubectl describe pod -n {{ include "node-exporter.namespace" . }} -l app.kubernetes.io/name={{ include "node-exporter.name" . }}
  
  High memory usage?
    â†’ Reduce enabled collectors in values.yaml
    â†’ Use edge-minimal preset for constrained devices
  
  Temperature metrics missing?
    â†’ Hardware may not expose thermal sensors
    â†’ Check: ls -la /sys/class/hwmon/
    â†’ Enable thermal_zone collector if available

ğŸ’¡ PRO TIPS (FROM ACTUAL PRODUCTION EXPERIENCE)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  1. ğŸ”¥ Monitor disk I/O on edge devices
     SSDs wear out, especially cheap consumer-grade ones in industrial environments.
     That WD Blue has seen better days.
  
  2. ğŸŒ¡ï¸  Watch temperatures in industrial enclosures
     Your edge device in a sealed metal box on the factory floor is NOT adequately
     cooled. Ask me how I know.
  
  3. ğŸ“Š Set up predictive disk full alerts
     Knowing your disk will be full in 3 days is better than knowing it's full NOW.
  
  4. ğŸ“ Use textfile collector for backup job status
     Export backup success/failure as metrics. Future you will thank present you.
  
  5. ğŸ”Œ Monitor network errors on industrial switches
     Industrial networks are noisy. High error rates are your early warning system.
  
  6. â° Track time drift
     Industrial systems often lack NTP. Time drift causes weird issues in logs.
  
  7. ğŸ’¾ Monitor RAID status if you have it
     Degraded RAID arrays don't announce themselves. Monitor or regret it later.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                      â”‚
â”‚  ğŸ¯ DEPLOYMENT COMPLETE                                                              â”‚
â”‚                                                                                      â”‚
â”‚  Your node metrics are now being collected. Set up alerts, import dashboards,       â”‚
â”‚  and enjoy knowing when your hardware is about to die BEFORE the smoke alarm        â”‚
â”‚  goes off.                                                                           â”‚
â”‚                                                                                      â”‚
â”‚  Because uptime matters when downtime costs actual money.                           â”‚
â”‚                                                                                      â”‚
â”‚  ğŸ”¥ Fireball Industries - Industrial automation that doesn't suck ğŸ”¥                 â”‚
â”‚                                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

P.S. - If you see temperature warnings above 80Â°C, that's not normal. Your edge
       device is literally cooking itself. Fix your cooling BEFORE you need to
       explain to management why production is down because a $400 industrial PC
       thermal-throttled itself into a kernel panic.

P.P.S. - Yes, I've seen a factory floor deployment where the "solution" to overheating
         was to point a desk fan at the enclosure. It worked... until someone
         unplugged the fan. Monitor your temps, people.
